{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3ebbef9",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center;\"><strong>ASSIGNMENT 4</strong></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50aaeca",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align:center;\"><strong>MOD300: Mandatory project 4</strong></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fd8055",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align:center;\"><strong>Group Members: Emad Omar Mohamed, Hassan Nehad Adnan, Sture Odin Domingos Troli</strong></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b029450",
   "metadata": {},
   "source": [
    "<h5 style=\"text-align:center;\">Dec 5, 2025</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a5cfcc",
   "metadata": {},
   "source": [
    "**Statement from the Group Members**\n",
    "\n",
    "We used limited AI assistance in this project, mainly to help debug code or to find solutions to code where otherwise we were stuck (functions, clustering algorithms,training the LSMT, and plotting) and to format text so it displays correctly in the Jupyter notebook.\n",
    "\n",
    "More specifically, our implementation is in Python using NumPy for array operations, scikit-learn for K-Means clustering, Matplotlib for plotting, and TensorFlow/Keras for neural networks and LSTM models, we were not successfull on all of it. We also used the mw_plot library for generating Milky Way visualizations as recommended in the Assignment 4 PDF. We used the free versions of Copilot and Gemini only to help debug several issues  that came up under the project (e.g., image array handling, cluster visualization, model training errors) and to fix some grammar mistakes in this report.\n",
    "\n",
    "We used some of the provided functions/classes Assignment_4 notebook template as well as created our owns, and the covid19_solution example from last year for structuring our report (specifically the text parts and overall organization). We used AI tools to help typeset formulas and improve grammar and clarity, as English is our second language for some even third or foruth. \n",
    "\n",
    "We structured the report with an abstract, introduction, brief explanations of each task for both Topic 1 (Milky Way clustering) and Topic 2 (epidemic prediction), a conclusion, and a summary of each member's contributions. This is consistent with our previous projects, while keeping the length relatively short without losing overall quality.\n",
    "\n",
    "All group members contributed to understanding the concepts, writing the code, and preparing this report. We believe this work represents our own learning and effort, with AI used only as a supporting tool for technical issues and language improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8100a4",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align:center;\"><strong>Abstract</strong></h4>\n",
    "\n",
    "In this project, two topics were explored: unsupervised learning for galaxy image analysis and supervised learning for epidemic prediction (using some rpevious experience from Assignment 2 - task 5).\n",
    "\n",
    "In Topic 1, we use \"unsupervised learning\" to study images of the Milky Way galaxy. We apply K-Means clustering to find different regions in the images without any labels. First, we create several pictures(4) of galaxy areas using the mw_plot Python library [1], with different centers (like M31, the Andromeda Galaxy) and different viewing sizes. We then change the images into RGB arrays, where each pixel has three numbers for Red, Green, and Blue - (RGB). We tested different ways to encode the data, including grayscale (brightness), brightness categories, and color-based groups.\n",
    "\n",
    "Our K-Means results with 5-7 clusters work well to split the galaxy images into clear parts: dark background (space), bright stars, and middle areas like dust and gas clouds. When we tried different numbers of clusters, 3 clusters are too simple, and more than 10 clusters add too much noise. With 5-7 clusters, we get good results where about 45% of pixels are dark regions, 35% are medium brightness, and 20% are bright star areas.\n",
    "\n",
    "We also compare two methods: using only color features (RGB) versus using color plus position (x, y coordinates). Adding position helps find connected regions, while color-only clustering better groups similar star types no matter where they are in the image [2]. The clusters we find do not automatically match real physical parts of the galaxy like spiral arms [3], but these methods are still useful for processing large amounts of astronomical data [4, 5].\n",
    "\n",
    "In Topic 2, we compare different ways to predict epidemic spread, using Ebola data from West Africa . We first reproduced the SEIR compartment model from previous work, then train several machine learning models: linear regression, polynomial regression, a basic neural network, and an LSTM network for time series [6]. We used data from Guinea, Liberia, and Sierra Leone to test which method works best.\n",
    "\n",
    "Our results show that no single method is best for everything. The SEIR model gives good predictions and is easy to understand because it uses real biology [7]. Linear regression is too simple for epidemic curves. Polynomial regression can fit the data well but may overfit. Neural networks can find complex patterns but are harder to interpret [8]. LSTM networks work well for time series but need more data to train properly.\n",
    "\n",
    "The main lesson  from Topic 2 in our opininon and experience,  is that we cannot just ignore traditional models and only use machine learning. Mathematical models like SEIR help us understand why diseases spread, while ML models are better at finding patterns in data. The best approach combines both methods [7, 8].\n",
    "\n",
    "Overall, this project shows that machine learning is a powerful tool for scientific problems [4], but it does has has its limits. In astronomy, clustering helps process millions of images [5, 6], but experts still need to interpret what the clusters mean. In epidemiology, ML can help with predictions, but domain knowledge is still needed to make good decisions. Both unsupervised and supervised learning work best when combined with human understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6d8442",
   "metadata": {},
   "source": [
    "#### **1 Introduction**\n",
    "\n",
    "This project studies two topics: unsupervised learning for astronomy and supervised learning for epidemic prediction. In Topic 1, we use machine learning to find patterns in images of the Milky Way galaxy, which has about 100–400 billion stars in a spiral shape [1,5].\n",
    "\n",
    "Because modern telescopes produce too much data to analyse by hand, we use unsupervised learning methods like K-Means clustering to group pixels by colour and brightness [2,4,6,7,8].\n",
    " \n",
    "We create images with the Python library **mw_plot** [1], turn them into RGB numbers, and then cluster them to see what kinds of regions the computer can find. In Topic 2, we use supervised learning to predict how diseases spread, using data from the Ebola epidemic in West Africa.\n",
    " \n",
    "We first reproduce results from a SEIR model [5], then test linear regression, polynomial regression, a simple neural network, and an LSTM network for time series data [7]. Our main goal is to see what these methods can do, where they fail, and how they can work together with traditional scientific models [4,5,6]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d6862d",
   "metadata": {},
   "source": [
    "# Task 0\n",
    "Task 0:  Install the python library from the page: milkyway-plot.readthedocs.io (from a jupyter notebook, run in a cell !pip  install mw_plot  Use a python environment! Ask \n",
    "the Tas in case of doubts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe0f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 0: Install Required Libraries\n",
    "# We had to install(only once, in the first time) this library for Milky Way visualizations\n",
    "# Install the missing dependencies\n",
    "\n",
    "!pip install scikit-learn\n",
    "!pip install bokeh\n",
    "!pip install mw_plot\n",
    "!pip install scikit-learn\n",
    "!pip install tensorflow\n",
    "!pip install astropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0f9ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy import units as u\n",
    "from mw_plot import MWFaceOn, MWSkyMap\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Importing the custom functions/ we didnt need to import nothing from PyGaLaXy as we have all the required functions in galaxy_functions_classes.py\n",
    "from galaxy_functions_classes import *\n",
    "from PyGaLaXy import *\n",
    "\n",
    "# Initially PyGaLaxy was working but then , ( from PyGaLaXy import * ) stopped working, so we used this command instead\n",
    "%run PyGaLaXy.ipynb\n",
    "\n",
    "# Setting plot style\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"This is a confirmation that all the libraries imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3f0f68",
   "metadata": {},
   "source": [
    "## Task 1: Reproduce the Milky Way Image via MWSkyMap\n",
    "\n",
    "We use the `mw_plot` package to generate a bird's eye view of the Milky Way galaxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7746d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Install the git package and reproduce the image of the milky way via MWSkyMap (see attached code). \n",
    "# in use PyGaLaXy.ipynb\n",
    "\n",
    "\n",
    "mw_facedown = MWFaceOn(\n",
    "    radius=20 * u.kpc,\n",
    "    unit=u.kpc,\n",
    "    coord=\"galactocentric\",\n",
    "    annotation=True,\n",
    "    figsize=(10, 8),\n",
    ")\n",
    "mw_facedown.title = \"Bird's Eyes View\"\n",
    "\n",
    "# Marking the Sun's position (approximately/cirka 8 kpc from galactic center)\n",
    "mw_facedown.scatter(8 * u.kpc, 0 * u.kpc, c=\"r\", s=50, label=\"Sun\")\n",
    "\n",
    "plt.show()\n",
    "print(\"Task 1 Complete: Milky Way face-on view generated. As asked in task 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52342e6",
   "metadata": {},
   "source": [
    "## Task 2: \n",
    "Generate a few (at least three in total) visualizations of the milky way sector starting in  different centers (try \"M31\") and with different radius (be careful on the units!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f82a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Generate a few (at least three in total) visualizations of the milky way sector \n",
    "# starting in different centers and with different radius (be careful on the units!).\n",
    "\n",
    "# The reason we are importing atropy and the other in each cell is because we were getting errors in each cell\n",
    "# the original plan was to have all the imports in the intial cell(THE CELL ABOVE TASK 1) but it was not working properly\n",
    "\n",
    "from astropy import units as u\n",
    "from mw_plot import MWSkyMap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ########################################################################################################################\n",
    "# View 1: M31 (Andromeda Galaxy) - close view\n",
    "# M31 coordinates: RA = 10.6847°, Dec = 41.2687°\n",
    "# ########################################################################################################################\n",
    "mw1 = MWSkyMap(\n",
    "    center=(10.6847, 41.2687) * u.deg,\n",
    "    radius=(2.5, 2.5) * u.deg,\n",
    "    background=\"optical\",\n",
    ")\n",
    "fig1, ax1 = plt.subplots(figsize=(8, 8))\n",
    "mw1.transform(ax1)\n",
    "ax1.set_title(\"View 1: M31 (Andromeda) - Radius: 2.5 deg\")\n",
    "plt.show()\n",
    "mw1.savefig('galaxy_m31.png')\n",
    "\n",
    "# ########################################################################################################################\n",
    "# View 2: M31 with larger radius (wider view)\n",
    "# Same center, bigger radius\n",
    "# ########################################################################################################################\n",
    "mw2 = MWSkyMap(\n",
    "    center=(10.6847, 41.2687) * u.deg,\n",
    "    radius=(5, 5) * u.deg,  # Larger radius\n",
    "    background=\"optical\",\n",
    ")\n",
    "fig2, ax2 = plt.subplots(figsize=(8, 8))\n",
    "mw2.transform(ax2)\n",
    "ax2.set_title(\"View 2: M31 (Andromeda) - Radius: 5 deg (wider)\")\n",
    "plt.show()\n",
    "\n",
    "# ########################################################################################################################\n",
    "# View 3: Orion Region (M42)\n",
    "# M42 coordinates: RA = 83.82°, Dec = -5.39°\n",
    "# ########################################################################################################################\n",
    "mw3 = MWSkyMap(\n",
    "    center=(83.82, -5.39) * u.deg,\n",
    "    radius=(5, 5) * u.deg,\n",
    "    background=\"optical\",\n",
    ")\n",
    "fig3, ax3 = plt.subplots(figsize=(8, 8))\n",
    "mw3.transform(ax3)\n",
    "ax3.set_title(\"View 3: Orion Region (M42) - Radius: 5 deg\")\n",
    "plt.show()\n",
    "\n",
    "# ########################################################################################################################\n",
    "# View 4 (We know the exercise only asked for 3 but we did one extra): Pleiades (M45)\n",
    "# M45 coordinates: RA = 56.60°, Dec = 24.11°\n",
    "# ########################################################################################################################\n",
    "mw4 = MWSkyMap(\n",
    "    center=(56.60, 24.11) * u.deg,\n",
    "    radius=(3, 3) * u.deg,\n",
    "    background=\"optical\",\n",
    ")\n",
    "fig4, ax4 = plt.subplots(figsize=(8, 8))\n",
    "mw4.transform(ax4)\n",
    "ax4.set_title(\"View 4: Pleiades (M45) - Radius: 3 deg\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Task 2 Complete: Generated 4 different visualizations.(the minimum was technically 3 but we did one extra one)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03d3519",
   "metadata": {},
   "source": [
    "## Task 3: \n",
    "Convert the image generated into a rgb np.array (each pixel will be a list of 3 number, Red, Green, Blue (rbg). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3052b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Convert the image generated into a RGB np.array (each pixel will be a list of 3 numbers: Red, Green, Blue (rgb)).\n",
    "\n",
    "# The reason we are importing numpy, matplotlib.pyplot, and the other libraries in each cell is because we were getting errors in each cell\n",
    "# the original plan was to have all the imports in the intial cell(THE CELL ABOVE TASK 1) but it was not working properly\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy import units as u\n",
    "from mw_plot import MWSkyMap\n",
    "\n",
    "# ########################################################################################################################\n",
    "# Function to convert matplotlib figure to RGB array\n",
    "# ########################################################################################################################\n",
    "def plt2rgbarr(fig):\n",
    "    \"\"\"\n",
    "    A function to transform a matplotlib figure to a 3D RGB np.array \n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    fig: matplotlib.figure.Figure\n",
    "        The plot that we want to encode.        \n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    np.array(height, width, 3): A 3D map of each pixel in RGB encoding\n",
    "        - First dimension: height (rows)\n",
    "        - Second dimension: width (columns)  \n",
    "        - Third dimension: RGB values (3 channels)\n",
    "    \"\"\"\n",
    "    # Removing padding around the axes for clean image\n",
    "    fig.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "    # Getting the RGBA buffer from the canvas\n",
    "    rgba_buf = fig.canvas.buffer_rgba()\n",
    "    w, h = fig.canvas.get_width_height()\n",
    "    \n",
    "    # Converting buffer to numpy array and reshape\n",
    "    rgba_arr = np.frombuffer(rgba_buf, dtype=np.uint8).reshape((h, w, 4))\n",
    "    \n",
    "    # Returning only RGB channels (drop alpha channel)\n",
    "    return rgba_arr[:, :, :3].copy()\n",
    "\n",
    "# ########################################################################################################################\n",
    "# Generate a fresh figure for conversion\n",
    "# Using M31 (Andromeda) as our main image\n",
    "# ########################################################################################################################\n",
    "mw_main = MWSkyMap(\n",
    "    center=(10.6847, 41.2687) * u.deg,\n",
    "    radius=(2.5, 2.5) * u.deg,\n",
    "    background=\"optical\",\n",
    ")\n",
    "fig_main, ax_main = plt.subplots(figsize=(8, 8))\n",
    "mw_main.transform(ax_main)\n",
    "ax_main.set_title(\"M31 - Image for RGB Conversion\")\n",
    "\n",
    "# ########################################################################################################################\n",
    "# Convert to RGB array\n",
    "# ########################################################################################################################\n",
    "rgb_array = plt2rgbarr(fig_main)\n",
    "\n",
    "# Display information about the array\n",
    "print(\"=\" * 60)\n",
    "print(\"RGB ARRAY INFORMATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Array Shape: {rgb_array.shape}\")\n",
    "print(f\"  - Height: {rgb_array.shape[0]} pixels\")\n",
    "print(f\"  - Width: {rgb_array.shape[1]} pixels\")\n",
    "print(f\"  - Channels: {rgb_array.shape[2]} (R, G, B)\")\n",
    "print(f\"Data type: {rgb_array.dtype}\")\n",
    "print(f\"Value range: [{rgb_array.min()}, {rgb_array.max()}]\")\n",
    "print(f\"Total pixels: {rgb_array.shape[0] * rgb_array.shape[1]:,}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Show the original figure\n",
    "plt.show()\n",
    "\n",
    "# ########################################################################################################################\n",
    "# Visualize the RGB array and individual channels\n",
    "# ########################################################################################################################\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "# Original RGB image\n",
    "axes[0, 0].imshow(rgb_array)\n",
    "axes[0, 0].set_title(\"Original RGB Image\")\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Red channel\n",
    "axes[0, 1].imshow(rgb_array[:, :, 0], cmap='Reds')\n",
    "axes[0, 1].set_title(\"Red Channel (R)\")\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# Green channel\n",
    "axes[1, 0].imshow(rgb_array[:, :, 1], cmap='Greens')\n",
    "axes[1, 0].set_title(\"Green Channel (G)\")\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "# Blue channel\n",
    "axes[1, 1].imshow(rgb_array[:, :, 2], cmap='Blues')\n",
    "axes[1, 1].set_title(\"Blue Channel (B)\")\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.suptitle(\"Task 3: RGB Array Decomposition\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ########################################################################################################################\n",
    "# Show a sample of pixel values\n",
    "# ########################################################################################################################\n",
    "print(\"\\nSample pixel values (first 5x5 pixels, Red channel):\")\n",
    "print(rgb_array[:5, :5, 0])\n",
    "\n",
    "print(\"\\nSample pixel at position [100, 100]:\")\n",
    "print(f\"  Red:   {rgb_array[100, 100, 0]}\")\n",
    "print(f\"  Green: {rgb_array[100, 100, 1]}\")\n",
    "print(f\"  Blue:  {rgb_array[100, 100, 2]}\")\n",
    "\n",
    "# Close the main figure to free memory\n",
    "plt.close(fig_main)\n",
    "\n",
    "print(\"\\nTask 3 Complete: Image converted to RGB numpy array.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477d4170",
   "metadata": {},
   "source": [
    "## Task 4: \n",
    "Ideate, describe in words and generate a set of categories from the task 3 data (e.g. red? Grey? ). This is your encoding.\n",
    "\n",
    "The The encoded data (grey_encoding, brightness_encoding, color_encoding) was used in Task 5 for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d8a4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Task 4: Ideate, describe in words and generate a set of categories from the task 3 data (e.g. red? Grey?). This is your encoding.\n",
    "\n",
    "# The reason we are importing numpy, matplotlib.pyplot, and the other libraries in each cell is because we were getting errors in each cell\n",
    "# the original plan was to have all the imports in the intial cell(THE CELL ABOVE TASK 1) but it was not working properly\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ########################################################################################################\n",
    "# ENCODING 1: Grayscale Encoding\n",
    "# ########################################################################################################\n",
    "def encode_grey(rgb_array):\n",
    "    \"\"\"\n",
    "    Converting RGB array to grayscale using standard luminosity weights.\n",
    "    \n",
    "    The weights (0.299, 0.587, 0.114) are based on human eye sensitivity:\n",
    "    - Human eyes are most sensitive to green\n",
    "    - Less sensitive to red\n",
    "    - Least sensitive to blue\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rgb_array : np.ndarray\n",
    "        3D array of shape (height, width, 3) with RGB values (0-255)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        2D array of shape (height, width) with grayscale values (0-255)\n",
    "    \"\"\"\n",
    "    # Standard luminosity weights for RGB to grayscale conversion\n",
    "    weights = np.array([0.299, 0.587, 0.114])\n",
    "    grey = np.sum(rgb_array * weights, axis=2)\n",
    "    return grey\n",
    "\n",
    "# #########################################################################################################\n",
    "# ENCODING 2: Brightness Categories\n",
    "# #########################################################################################################\n",
    "def encode_brightness_category(rgb_array, n_categories=5):\n",
    "    \"\"\"\n",
    "    Encode pixels into discrete brightness categories.\n",
    "    \n",
    "    Categories divide the brightness range (0-255) into equal segments:\n",
    "    - Category 0: Very Dark (0-51)\n",
    "    - Category 1: Dark (51-102)\n",
    "    - Category 2: Medium (102-153)\n",
    "    - Category 3: Bright (153-204)\n",
    "    - Category 4: Very Bright (204-255)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rgb_array : np.ndarray\n",
    "        3D array of shape (height, width, 3) with RGB values\n",
    "    n_categories : int\n",
    "        Number of brightness categories (default: 5)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        2D array with category labels (0 to n_categories-1)\n",
    "    \"\"\"\n",
    "    # First convert to grayscale\n",
    "    grey = encode_grey(rgb_array)\n",
    "    \n",
    "    # Calculate thresholds for equal-width bins\n",
    "    thresholds = np.linspace(0, 255, n_categories + 1)[1:-1]\n",
    "    \n",
    "    # Assign categories\n",
    "    categories = np.zeros_like(grey, dtype=int)\n",
    "    for i, threshold in enumerate(thresholds):\n",
    "        categories[grey > threshold] = i + 1\n",
    "        \n",
    "    return categories, thresholds\n",
    "\n",
    "# #########################################################################################################\n",
    "# ENCODING 3: Color Categories\n",
    "# #########################################################################################################\n",
    "def encode_color_category(rgb_array):\n",
    "    \"\"\"\n",
    "    Encode pixels into color categories based on dominant RGB channel.\n",
    "    \n",
    "    Categories:\n",
    "    - 0: Dark (all channels below dark_threshold)\n",
    "    - 1: Red dominant (R > G and R > B)\n",
    "    - 2: Green dominant (G > R and G > B)\n",
    "    - 3: Blue dominant (B > R and B > G)\n",
    "    - 4: Bright/White (all channels above bright_threshold)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rgb_array : np.ndarray\n",
    "        3D array of shape (height, width, 3) with RGB values\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (category_array, category_labels_dict)\n",
    "    \"\"\"\n",
    "    # Extract individual channels\n",
    "    r = rgb_array[:, :, 0].astype(float)\n",
    "    g = rgb_array[:, :, 1].astype(float)\n",
    "    b = rgb_array[:, :, 2].astype(float)\n",
    "    \n",
    "    # Calculate grayscale for brightness check\n",
    "    grey = encode_grey(rgb_array)\n",
    "    \n",
    "    # Initialize categories array\n",
    "    categories = np.zeros(rgb_array.shape[:2], dtype=int)\n",
    "    \n",
    "    # Define thresholds\n",
    "    dark_threshold = 50\n",
    "    bright_threshold = 200\n",
    "    \n",
    "    # Category 0: Dark pixels\n",
    "    categories[grey < dark_threshold] = 0\n",
    "    \n",
    "    # Category 4: Bright/White pixels (all channels high)\n",
    "    is_bright = (r > bright_threshold) & (g > bright_threshold) & (b > bright_threshold)\n",
    "    categories[is_bright] = 4\n",
    "    \n",
    "    # For remaining pixels, find dominant color\n",
    "    mask_middle = (grey >= dark_threshold) & (~is_bright)\n",
    "    \n",
    "    # Category 1: Red dominant\n",
    "    red_dominant = mask_middle & (r > g) & (r > b)\n",
    "    categories[red_dominant] = 1\n",
    "    \n",
    "    # Category 2: Green dominant\n",
    "    green_dominant = mask_middle & (g > r) & (g > b)\n",
    "    categories[green_dominant] = 2\n",
    "    \n",
    "    # Category 3: Blue dominant\n",
    "    blue_dominant = mask_middle & (b > r) & (b > g)\n",
    "    categories[blue_dominant] = 3\n",
    "    \n",
    "    # Labels dictionary for reference\n",
    "    labels = {\n",
    "        0: \"Dark\",\n",
    "        1: \"Red Dominant\",\n",
    "        2: \"Green Dominant\",\n",
    "        3: \"Blue Dominant\",\n",
    "        4: \"Bright/White\"\n",
    "    }\n",
    "    \n",
    "    return categories, labels\n",
    "\n",
    "# #########################################################################################################\n",
    "# Apply all encodings to our rgb_array\n",
    "# #########################################################################################################\n",
    "\n",
    "# Encoding 1: Grayscale\n",
    "grey_encoding = encode_grey(rgb_array)\n",
    "print(\"=\" * 60)\n",
    "print(\"ENCODING 1: GRAYSCALE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Shape: {grey_encoding.shape}\")\n",
    "print(f\"Value range: [{grey_encoding.min():.2f}, {grey_encoding.max():.2f}]\")\n",
    "print(f\"Mean brightness: {grey_encoding.mean():.2f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Encoding 2: Brightness Categories\n",
    "brightness_encoding, thresholds = encode_brightness_category(rgb_array, n_categories=5)\n",
    "print(\"\\nENCODING 2: BRIGHTNESS CATEGORIES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Number of categories: {len(np.unique(brightness_encoding))}\")\n",
    "print(f\"Thresholds: {thresholds}\")\n",
    "print(\"\\nCategory distribution:\")\n",
    "for cat in range(5):\n",
    "    count = np.sum(brightness_encoding == cat)\n",
    "    percentage = 100 * count / brightness_encoding.size\n",
    "    cat_names = [\"Very Dark\", \"Dark\", \"Medium\", \"Bright\", \"Very Bright\"]\n",
    "    print(f\"  Category {cat} ({cat_names[cat]}): {count:,} pixels ({percentage:.2f}%)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Encoding 3: Color Categories\n",
    "color_encoding, color_labels = encode_color_category(rgb_array)\n",
    "print(\"\\nENCODING 3: COLOR CATEGORIES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Number of categories: {len(np.unique(color_encoding))}\")\n",
    "print(\"\\nCategory distribution:\")\n",
    "for cat_id, label in color_labels.items():\n",
    "    count = np.sum(color_encoding == cat_id)\n",
    "    percentage = 100 * count / color_encoding.size\n",
    "    print(f\"  Category {cat_id} ({label}): {count:,} pixels ({percentage:.2f}%)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# #########################################################################################################\n",
    "# Visualize all encodings\n",
    "# #########################################################################################################\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Original RGB image\n",
    "axes[0, 0].imshow(rgb_array)\n",
    "axes[0, 0].set_title(\"Original RGB Image\", fontsize=12, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Grayscale encoding\n",
    "im1 = axes[0, 1].imshow(grey_encoding, cmap='gray')\n",
    "axes[0, 1].set_title(\"Encoding 1: Grayscale\", fontsize=12, fontweight='bold')\n",
    "axes[0, 1].axis('off')\n",
    "plt.colorbar(im1, ax=axes[0, 1], fraction=0.046, label='Intensity (0-255)')\n",
    "\n",
    "# Brightness categories\n",
    "im2 = axes[1, 0].imshow(brightness_encoding, cmap='viridis')\n",
    "axes[1, 0].set_title(\"Encoding 2: Brightness Categories (5 levels)\", fontsize=12, fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "cbar2 = plt.colorbar(im2, ax=axes[1, 0], fraction=0.046, ticks=[0, 1, 2, 3, 4])\n",
    "cbar2.ax.set_yticklabels(['Very Dark', 'Dark', 'Medium', 'Bright', 'Very Bright'])\n",
    "\n",
    "# Color categories\n",
    "im3 = axes[1, 1].imshow(color_encoding, cmap='tab10')\n",
    "axes[1, 1].set_title(\"Encoding 3: Color Categories\", fontsize=12, fontweight='bold')\n",
    "axes[1, 1].axis('off')\n",
    "cbar3 = plt.colorbar(im3, ax=axes[1, 1], fraction=0.046, ticks=[0, 1, 2, 3, 4])\n",
    "cbar3.ax.set_yticklabels(['Dark', 'Red', 'Green', 'Blue', 'Bright'])\n",
    "\n",
    "plt.suptitle(\"Task 4: Different Encoding Schemes for Galaxy Image\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f19d99c",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "Use K-NN (Nearest neighbor, not discussed in class but extremely simple) or K-means to cluster the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeed1a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLUSTERING EXPERIMENT 1: K-Means with 5 clusters (RGB features only)\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rgb_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 121\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m    119\u001b[39m n_clusters = \u001b[32m5\u001b[39m\n\u001b[32m    120\u001b[39m cluster_labels_5, kmeans_model_5 = cluster_kmeans(\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     \u001b[43mrgb_array\u001b[49m, \n\u001b[32m    122\u001b[39m     n_clusters=n_clusters, \n\u001b[32m    123\u001b[39m     include_position=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    124\u001b[39m )\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# Print statistics\u001b[39;00m\n\u001b[32m    127\u001b[39m stats_5 = get_cluster_statistics(cluster_labels_5)\n",
      "\u001b[31mNameError\u001b[39m: name 'rgb_array' is not defined"
     ]
    }
   ],
   "source": [
    "# Task 5: Use K-NN (Nearest neighbor, not discussed in class but extremely simple) or K-means to cluster the data\n",
    "\n",
    "# The reason we are importing numpy, matplotlib.pyplot, and the other libraries in each cell is because we were getting errors in each cell\n",
    "# the original plan was to have all the imports in the intial cell(THE CELL ABOVE TASK 1) but it was not working properly\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ###################################################################################################################################\n",
    "# Function to perform K-Means clustering on RGB array\n",
    "# ###################################################################################################################################\n",
    "def cluster_kmeans(rgb_array, n_clusters=5, include_position=False, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform K-Means clustering on pixel data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rgb_array : np.ndarray\n",
    "        3D RGB array of shape (height, width, 3)\n",
    "    n_clusters : int\n",
    "        Number of clusters to create\n",
    "    include_position : bool\n",
    "        If True, include (x, y) pixel position as features\n",
    "    random_state : int\n",
    "        Random seed for reproducibility\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (cluster_labels_2d, kmeans_model) - Labels reshaped to image dimensions and the model\n",
    "    \"\"\"\n",
    "    h, w = rgb_array.shape[:2]\n",
    "    \n",
    "    # Flatten RGB array to 2D: (n_pixels, 3)\n",
    "    features = rgb_array.reshape(-1, 3).astype(float)\n",
    "    \n",
    "    if include_position:\n",
    "        # Create coordinate grids\n",
    "        y_coords, x_coords = np.mgrid[0:h, 0:w]\n",
    "        x_flat = x_coords.flatten()\n",
    "        y_flat = y_coords.flatten()\n",
    "        \n",
    "        # Normalize position to same scale as color values (0-255)\n",
    "        x_norm = (x_flat / w) * 255\n",
    "        y_norm = (y_flat / h) * 255\n",
    "        \n",
    "        # Add position to features\n",
    "        features = np.column_stack([features, x_norm, y_norm])\n",
    "    \n",
    "    # Standardize features (important for K-Means)\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    # Perform K-Means clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=10)\n",
    "    labels = kmeans.fit_predict(features_scaled)\n",
    "    \n",
    "    # Reshape labels back to image dimensions\n",
    "    labels_2d = labels.reshape(h, w)\n",
    "    \n",
    "    return labels_2d, kmeans\n",
    "\n",
    "# ###################################################################################################################################\n",
    "# Function to get cluster statistics\n",
    "# ###################################################################################################################################\n",
    "def get_cluster_statistics(cluster_labels):\n",
    "    \"\"\"\n",
    "    Calculate statistics about cluster distribution.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cluster_labels : np.ndarray\n",
    "        2D array of cluster labels\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary with cluster statistics\n",
    "    \"\"\"\n",
    "    unique, counts = np.unique(cluster_labels, return_counts=True)\n",
    "    total = cluster_labels.size\n",
    "    \n",
    "    stats = {\n",
    "        \"n_clusters\": len(unique),\n",
    "        \"total_pixels\": total,\n",
    "        \"cluster_counts\": dict(zip(unique.tolist(), counts.tolist())),\n",
    "        \"cluster_percentages\": {\n",
    "            int(u): round(100 * c / total, 2) \n",
    "            for u, c in zip(unique, counts)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# ###################################################################################################################################\n",
    "# Function to print cluster summary\n",
    "# ###################################################################################################################################\n",
    "def print_cluster_summary(stats):\n",
    "    \"\"\"Print a formatted summary of cluster statistics.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"CLUSTER ANALYSIS SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Number of clusters: {stats['n_clusters']}\")\n",
    "    print(f\"Total pixels: {stats['total_pixels']:,}\")\n",
    "    print(f\"\\nCluster distribution:\")\n",
    "    for cluster_id, percentage in stats['cluster_percentages'].items():\n",
    "        count = stats['cluster_counts'][cluster_id]\n",
    "        print(f\"  Cluster {cluster_id}: {count:,} pixels ({percentage:.2f}%)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# ###################################################################################################################################\n",
    "# CLUSTERING EXPERIMENT 1: K-Means with 5 clusters (RGB only)\n",
    "# ###################################################################################################################################\n",
    "print(\"CLUSTERING EXPERIMENT 1: K-Means with 5 clusters (RGB features only)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "n_clusters = 5\n",
    "cluster_labels_5, kmeans_model_5 = cluster_kmeans(\n",
    "    rgb_array, \n",
    "    n_clusters=n_clusters, \n",
    "    include_position=False\n",
    ")\n",
    "\n",
    "# Print statistics\n",
    "stats_5 = get_cluster_statistics(cluster_labels_5)\n",
    "print_cluster_summary(stats_5)\n",
    "\n",
    "# ###################################################################################################################################\n",
    "# CLUSTERING EXPERIMENT 2: K-Means with 7 clusters (RGB only)\n",
    "# ###################################################################################################################################\n",
    "print(\"\\nCLUSTERING EXPERIMENT 2: K-Means with 7 clusters (RGB features only)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "cluster_labels_7, kmeans_model_7 = cluster_kmeans(\n",
    "    rgb_array, \n",
    "    n_clusters=7, \n",
    "    include_position=False\n",
    ")\n",
    "\n",
    "stats_7 = get_cluster_statistics(cluster_labels_7)\n",
    "print_cluster_summary(stats_7)\n",
    "\n",
    "# ###################################################################################################################################\n",
    "# CLUSTERING EXPERIMENT 3: K-Means with position features\n",
    "# ###################################################################################################################################\n",
    "print(\"\\nCLUSTERING EXPERIMENT 3: K-Means with 5 clusters (RGB + Position)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "cluster_labels_pos, kmeans_model_pos = cluster_kmeans(\n",
    "    rgb_array, \n",
    "    n_clusters=5, \n",
    "    include_position=True\n",
    ")\n",
    "\n",
    "stats_pos = get_cluster_statistics(cluster_labels_pos)\n",
    "print_cluster_summary(stats_pos)\n",
    "\n",
    "# ###################################################################################################################################\n",
    "# Visualize clustering results\n",
    "# ###################################################################################################################################\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Original image\n",
    "axes[0, 0].imshow(rgb_array)\n",
    "axes[0, 0].set_title(\"Original RGB Image\", fontsize=12, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# 5 clusters (RGB only)\n",
    "im1 = axes[0, 1].imshow(cluster_labels_5, cmap='tab10')\n",
    "axes[0, 1].set_title(\"K-Means: 5 Clusters (RGB only)\", fontsize=12, fontweight='bold')\n",
    "axes[0, 1].axis('off')\n",
    "plt.colorbar(im1, ax=axes[0, 1], fraction=0.046, label='Cluster ID')\n",
    "\n",
    "# 7 clusters (RGB only)\n",
    "im2 = axes[1, 0].imshow(cluster_labels_7, cmap='tab10')\n",
    "axes[1, 0].set_title(\"K-Means: 7 Clusters (RGB only)\", fontsize=12, fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "plt.colorbar(im2, ax=axes[1, 0], fraction=0.046, label='Cluster ID')\n",
    "\n",
    "# 5 clusters (RGB + Position)\n",
    "im3 = axes[1, 1].imshow(cluster_labels_pos, cmap='tab10')\n",
    "axes[1, 1].set_title(\"K-Means: 5 Clusters (RGB + Position)\", fontsize=12, fontweight='bold')\n",
    "axes[1, 1].axis('off')\n",
    "plt.colorbar(im3, ax=axes[1, 1], fraction=0.046, label='Cluster ID')\n",
    "\n",
    "plt.suptitle(\"Task 5: K-Means Clustering Results\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ###################################################################################################################################\n",
    "# Compare different numbers of clusters\n",
    "# ###################################################################################################################################\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPARING DIFFERENT CLUSTER COUNTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "fig2, axes2 = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes2 = axes2.flatten()\n",
    "\n",
    "cluster_counts = [3, 4, 5, 6, 7, 10]\n",
    "\n",
    "for i, n_clust in enumerate(cluster_counts):\n",
    "    labels, _ = cluster_kmeans(rgb_array, n_clusters=n_clust)\n",
    "    axes2[i].imshow(labels, cmap='tab10')\n",
    "    axes2[i].set_title(f\"K-Means: {n_clust} Clusters\", fontsize=11, fontweight='bold')\n",
    "    axes2[i].axis('off')\n",
    "\n",
    "plt.suptitle(\"Comparison of Different Cluster Counts\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ###################################################################################################################################\n",
    "# Analyze what each cluster represents\n",
    "# ###################################################################################################################################\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CLUSTER ANALYSIS: What does each cluster represent?\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# For 5-cluster solution, analyze mean RGB values per cluster\n",
    "print(\"\\nMean RGB values for each cluster (5-cluster solution):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for cluster_id in range(5):\n",
    "    # Get mask for this cluster\n",
    "    mask = cluster_labels_5 == cluster_id\n",
    "    \n",
    "    # Calculate mean RGB values for pixels in this cluster\n",
    "    mean_r = rgb_array[:, :, 0][mask].mean()\n",
    "    mean_g = rgb_array[:, :, 1][mask].mean()\n",
    "    mean_b = rgb_array[:, :, 2][mask].mean()\n",
    "    mean_brightness = (0.299 * mean_r + 0.587 * mean_g + 0.114 * mean_b)\n",
    "    \n",
    "    # Determine cluster type based on values\n",
    "    if mean_brightness < 50:\n",
    "        cluster_type = \"Dark space / Background\"\n",
    "    elif mean_brightness < 100:\n",
    "        cluster_type = \"Dim regions\"\n",
    "    elif mean_brightness < 150:\n",
    "        cluster_type = \"Medium brightness\"\n",
    "    elif mean_brightness < 200:\n",
    "        cluster_type = \"Bright regions\"\n",
    "    else:\n",
    "        cluster_type = \"Very bright / Stars\"\n",
    "    \n",
    "    print(f\"Cluster {cluster_id}:\")\n",
    "    print(f\"  Mean RGB: ({mean_r:.1f}, {mean_g:.1f}, {mean_b:.1f})\")\n",
    "    print(f\"  Mean Brightness: {mean_brightness:.1f}\")\n",
    "    print(f\"  Interpretation: {cluster_type}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5adc89",
   "metadata": {},
   "source": [
    "# Task 5\n",
    "K-Means is a clustering algorithm that groups data into K groups by randomly placing center points, assigning each pixel to the nearest center, and \n",
    "repeating until the groups stop changing. We used it to group galaxy pixels by their colors. We found that 5-7 clusters works best - fewer is too simple \n",
    "and more just picks up noise. Adding position data along with RGB colors helps create clusters that are connected in space. The dark clusters show \n",
    "empty space, medium clusters show dust and dim light, and bright clusters show stars. This method is useful for automatically separating regions and \n",
    "finding stars in galaxy images.\n",
    "\n",
    "We found that using 5-7 clusters works best for galaxy images - using fewer oversimplifies things and using more just captures noise. Adding position \n",
    "data to RGB colors helps create clusters that stick together in space rather than just grouping similar colors from anywhere in the image. The clusters \n",
    "are easy to interpret: dark ones are empty space, medium ones are dust and dim light, and bright ones are stars. This technique is useful for \n",
    "automatically separating different regions in images and finding stars.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1605f177",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "\n",
    "Over-impose your cluster to the image generated in task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf91e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6: Over-impose your cluster to the image generated in task 2 \n",
    "\n",
    "# The reason we are importing numpy, matplotlib.pyplot, and the other libraries in each cell is because we were getting errors in each cell\n",
    "# the original plan was to have all the imports in the intial cell(THE CELL ABOVE TASK 1) but it was not working properly\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# ################################################################################################################\n",
    "# Function to overlay clusters on image\n",
    "# ################################################################################################################\n",
    "def overlay_clusters_on_image(rgb_array, cluster_labels, alpha=0.4, cmap='tab10', title=\"Clusters Overlaid\"):\n",
    "    \"\"\"\n",
    "    Overlay cluster labels on the original RGB image.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rgb_array : np.ndarray\n",
    "        Original RGB image array\n",
    "    cluster_labels : np.ndarray\n",
    "        2D array of cluster labels\n",
    "    alpha : float\n",
    "        Transparency of cluster overlay (0=invisible, 1=opaque)\n",
    "    cmap : str\n",
    "        Colormap for cluster visualization\n",
    "    title : str\n",
    "        Plot title\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The generated figure\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    \n",
    "    # Show original image\n",
    "    ax.imshow(rgb_array)\n",
    "    \n",
    "    # Overlay clusters with transparency\n",
    "    im = ax.imshow(cluster_labels, cmap=cmap, alpha=alpha)\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.set_label('Cluster ID', fontsize=11)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# #################################################################################################################\n",
    "# OVERLAY 1: 5 Clusters (RGB only) on original image\n",
    "# #################################################################################################################\n",
    "print(\"=\" * 60)\n",
    "print(\"TASK 6: OVERLAYING CLUSTERS ON ORIGINAL IMAGE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "fig1 = overlay_clusters_on_image(\n",
    "    rgb_array, \n",
    "    cluster_labels_5, \n",
    "    alpha=0.4,\n",
    "    title=\"Overlay: 5 Clusters (RGB only) - Alpha=0.4\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# #################################################################################################################\n",
    "# OVERLAY 2: Compare different transparency levels\n",
    "# #################################################################################################################\n",
    "print(\"\\nComparing different transparency (alpha) levels...\")\n",
    "\n",
    "fig2, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Original image (no overlay)\n",
    "axes[0, 0].imshow(rgb_array)\n",
    "axes[0, 0].set_title(\"Original Image (No Overlay)\", fontsize=12, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Alpha = 0.3 (more transparent)\n",
    "axes[0, 1].imshow(rgb_array)\n",
    "im1 = axes[0, 1].imshow(cluster_labels_5, cmap='tab10', alpha=0.3)\n",
    "axes[0, 1].set_title(\"Overlay: Alpha = 0.3 (More Transparent)\", fontsize=12, fontweight='bold')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# Alpha = 0.5 (medium)\n",
    "axes[1, 0].imshow(rgb_array)\n",
    "im2 = axes[1, 0].imshow(cluster_labels_5, cmap='tab10', alpha=0.5)\n",
    "axes[1, 0].set_title(\"Overlay: Alpha = 0.5 (Medium)\", fontsize=12, fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "# Alpha = 0.7 (less transparent)\n",
    "axes[1, 1].imshow(rgb_array)\n",
    "im3 = axes[1, 1].imshow(cluster_labels_5, cmap='tab10', alpha=0.7)\n",
    "axes[1, 1].set_title(\"Overlay: Alpha = 0.7 (Less Transparent)\", fontsize=12, fontweight='bold')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.suptitle(\"Comparison of Different Transparency Levels\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# #################################################################################################################\n",
    "# OVERLAY 3: Side-by-side comparison\n",
    "# #################################################################################################################\n",
    "print(\"\\nSide-by-side comparison: Original vs Clusters vs Overlay...\")\n",
    "\n",
    "fig3, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Original image\n",
    "axes[0].imshow(rgb_array)\n",
    "axes[0].set_title(\"Original Galaxy Image\", fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Cluster map only\n",
    "im_clusters = axes[1].imshow(cluster_labels_5, cmap='tab10')\n",
    "axes[1].set_title(\"Cluster Map (5 Clusters)\", fontsize=12, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "plt.colorbar(im_clusters, ax=axes[1], fraction=0.046, label='Cluster ID')\n",
    "\n",
    "# Overlay\n",
    "axes[2].imshow(rgb_array)\n",
    "im_overlay = axes[2].imshow(cluster_labels_5, cmap='tab10', alpha=0.4)\n",
    "axes[2].set_title(\"Clusters Overlaid on Image\", fontsize=12, fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "plt.colorbar(im_overlay, ax=axes[2], fraction=0.046, label='Cluster ID')\n",
    "\n",
    "plt.suptitle(\"Task 6: Cluster Overlay Comparison\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# #################################################################################################################\n",
    "# OVERLAY 4: Compare different clustering results\n",
    "# #################################################################################################################\n",
    "print(\"\\nComparing overlays with different cluster counts...\")\n",
    "\n",
    "fig4, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# 5 clusters overlay\n",
    "axes[0, 0].imshow(rgb_array)\n",
    "axes[0, 0].imshow(cluster_labels_5, cmap='tab10', alpha=0.4)\n",
    "axes[0, 0].set_title(\"5 Clusters (RGB only)\", fontsize=12, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# 7 clusters overlay\n",
    "axes[0, 1].imshow(rgb_array)\n",
    "axes[0, 1].imshow(cluster_labels_7, cmap='tab10', alpha=0.4)\n",
    "axes[0, 1].set_title(\"7 Clusters (RGB only)\", fontsize=12, fontweight='bold')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# 5 clusters with position overlay\n",
    "axes[1, 0].imshow(rgb_array)\n",
    "axes[1, 0].imshow(cluster_labels_pos, cmap='tab10', alpha=0.4)\n",
    "axes[1, 0].set_title(\"5 Clusters (RGB + Position)\", fontsize=12, fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "# 3 clusters for comparison\n",
    "cluster_labels_3, _ = cluster_kmeans(rgb_array, n_clusters=3)\n",
    "axes[1, 1].imshow(rgb_array)\n",
    "axes[1, 1].imshow(cluster_labels_3, cmap='tab10', alpha=0.4)\n",
    "axes[1, 1].set_title(\"3 Clusters (RGB only)\", fontsize=12, fontweight='bold')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.suptitle(\"Comparison of Different Clustering Approaches Overlaid\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# #################################################################################################################\n",
    "# OVERLAY 5: Highlight specific clusters\n",
    "# #################################################################################################################\n",
    "print(\"\\nHighlighting individual clusters...\")\n",
    "\n",
    "fig5, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Show each cluster individually\n",
    "for i in range(5):\n",
    "    # Create mask for this cluster\n",
    "    mask = (cluster_labels_5 == i).astype(float)\n",
    "    \n",
    "    # Show original image\n",
    "    axes[i].imshow(rgb_array)\n",
    "    \n",
    "    # Overlay only this cluster (highlighted in red)\n",
    "    cluster_highlight = np.zeros((*cluster_labels_5.shape, 4))  # RGBA\n",
    "    cluster_highlight[cluster_labels_5 == i] = [1, 0, 0, 0.5]  # Red with 50% alpha\n",
    "    \n",
    "    axes[i].imshow(cluster_highlight)\n",
    "    \n",
    "    # Calculate percentage\n",
    "    percentage = 100 * np.sum(cluster_labels_5 == i) / cluster_labels_5.size\n",
    "    axes[i].set_title(f\"Cluster {i} Highlighted ({percentage:.1f}%)\", fontsize=11, fontweight='bold')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# Use last subplot for legend/info\n",
    "axes[5].axis('off')\n",
    "axes[5].text(0.5, 0.5, \n",
    "    \"Individual Cluster\\nHighlights\\n\\nRed overlay shows\\npixels belonging to\\neach cluster\",\n",
    "    ha='center', va='center', fontsize=12,\n",
    "    transform=axes[5].transAxes,\n",
    "    bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "\n",
    "plt.suptitle(\"Individual Clusters Highlighted on Original Image\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# #################################################################################################################\n",
    "# Save the best overlay result\n",
    "# #################################################################################################################\n",
    "print(\"\\nSaving overlay result to file...\")\n",
    "\n",
    "fig_save, ax_save = plt.subplots(figsize=(10, 10))\n",
    "ax_save.imshow(rgb_array)\n",
    "ax_save.imshow(cluster_labels_5, cmap='tab10', alpha=0.4)\n",
    "ax_save.set_title(\"Galaxy Clustering Result - 5 Clusters\", fontsize=14, fontweight='bold')\n",
    "ax_save.axis('off')\n",
    "plt.savefig('galaxy_clusters_overlay.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved as 'galaxy_clusters_overlay.png'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b2a59e",
   "metadata": {},
   "source": [
    "## Task 7: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a18eef",
   "metadata": {},
   "source": [
    "## **TOPIC 2: Supervised learning: Machines versus human models, who can save the world??**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca1b539",
   "metadata": {},
   "source": [
    "## Task 0: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0efc718",
   "metadata": {},
   "source": [
    "## Task 1: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cd66fe",
   "metadata": {},
   "source": [
    "\n",
    "# Task 2:\n",
    "Train a better fitting function than a single line with linear regression on the data for the three countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e84b0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "for idx, (country, cdata) in enumerate(data.items()):\n",
    "    ax = axes[idx]\n",
    "    days, cumulative = cdata['days'], cdata['cumulative']\n",
    "    ax.scatter(days, cumulative, color='red', alpha=0.6, s=40, label='Data')\n",
    "    ax.plot(days, linear_results[country]['predictions'], '--', color='gray', label='Linear')\n",
    "    _, _, pred_poly, metrics_poly = polynomial_fit(days, cumulative, degree=3)\n",
    "    ax.plot(days, pred_poly, '-', color='blue', linewidth=2, label=f'Poly(3) R2={metrics_poly[\"r2\"]:.3f}')\n",
    "    params, pred_sig, metrics_sig = fit_sigmoid(days, cumulative)\n",
    "    if pred_sig is not None:\n",
    "        ax.plot(days, pred_sig, '-', color='green', linewidth=2, label=f'Sigmoid R2={metrics_sig[\"r2\"]:.3f}')\n",
    "    ax.set_title(f'{country}', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('task2_better_fits.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca24164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined fit\n",
    "all_days, all_cumulative, combined_results = combined_fit_all_countries(data)\n",
    "print('Combined Fitting Results:')\n",
    "for method, res in combined_results.items():\n",
    "    print(f'  {method}: R2={res[\"metrics\"][\"r2\"]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbd606b",
   "metadata": {},
   "source": [
    "## Task 3: \n",
    "Train a NN network and predict the epidemic evolution. Careful here in your training/test split, remember the assumptions you need to take here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd04a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_results = nn_predict_epidemic(data, test_size=0.2)\n",
    "print('Neural Network Results:')\n",
    "for country, res in nn_results.items():\n",
    "    print(f'  {country}: R2={res[\"metrics\"][\"r2\"]:.4f}, RMSE={res[\"metrics\"][\"rmse\"]:.1f}')\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "for idx, (country, res) in enumerate(nn_results.items()):\n",
    "    ax = axes[idx]\n",
    "    ax.scatter(res['X_train'], res['y_train'], color='blue', alpha=0.5, s=30, label='Train')\n",
    "    ax.scatter(res['X_test'], res['y_test'], color='red', alpha=0.7, s=50, label='Test')\n",
    "    ax.scatter(res['X_test'], res['y_pred'], color='green', marker='x', s=80, label='Predicted')\n",
    "    ax.set_title(f'{country} - NN R2={res[\"metrics\"][\"r2\"]:.3f}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('task3_nn.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd098a1",
   "metadata": {},
   "source": [
    "\n",
    "# Task 4:\n",
    "Train a LSTM (a NN specialized for time series) and predict the epidemic evolution.\n",
    "\n",
    "(More points here available because I did not provide a code for this, this is a bit of self-learning \n",
    "task, I suggest to refer to https://machinelearningmastery.com/time-series-prediction-lstm recurrent-neural-networks-python-keras/). \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509d6c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if TensorFlow is available before running any LSTM models\n",
    "if TF_AVAILABLE:\n",
    "    lstm_results = lstm_predict_all_countries(data, seq_length=5, test_size=0.2, epochs=100)\n",
    "    print('LSTM Results:')\n",
    "\n",
    "     # Loop through each country’s result and print the R² score\n",
    "    for country, res in lstm_results.items():\n",
    "        if res['metrics']:\n",
    "            print(f'  {country}: R2={res[\"metrics\"][\"r2\"]:.4f}')\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "     # Plot actual vs predicted values for each country\n",
    "    for idx, (country, res) in enumerate(lstm_results.items()):\n",
    "        ax = axes[idx]\n",
    "        if res['y_pred'] is not None:\n",
    "            ax.plot(res['y_test'], 'b-', linewidth=2, label='Actual')\n",
    "            ax.plot(res['y_pred'], 'r--', linewidth=2, label='Predicted')\n",
    "            ax.set_title(f'{country} - LSTM R2={res[\"metrics\"][\"r2\"]:.3f}')\n",
    "            ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('task4_lstm.png', dpi=150)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('TensorFlow not available for LSTM*(we initially were not able to run Tensor thets why we created a flag TF_AVAILABLE)')\n",
    "    lstm_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c384db3",
   "metadata": {},
   "source": [
    "## Task 5: \n",
    "Discuss the results. Can we ignore modeling and let Machine Leaning make prediction? What is a good prediction for these cases? What are your conclusions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abeb5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare SEIR parameters for the comparison function\n",
    "seir_params = {'sigma': sigma, 'gamma': gamma, 'N': N}\n",
    "comparison_df = compare_all_methods(data, seir_params)\n",
    "\n",
    "# Add Neural Network results into the comparison DataFrame\n",
    "for country, res in nn_results.items():\n",
    "    comparison_df = pd.concat([comparison_df, pd.DataFrame([{\n",
    "        'Country': country, 'Method': 'Neural Network',\n",
    "        'R2': res['metrics']['r2'], 'RMSE': res['metrics']['rmse']\n",
    "    }])], ignore_index=True)\n",
    "\n",
    "# Add LSTM results\n",
    "if lstm_results:\n",
    "    for country, res in lstm_results.items():\n",
    "        if res['metrics']:\n",
    "            comparison_df = pd.concat([comparison_df, pd.DataFrame([{\n",
    "                'Country': country, 'Method': 'LSTM',\n",
    "                'R2': res['metrics']['r2'], 'RMSE': res['metrics']['rmse']\n",
    "            }])], ignore_index=True)\n",
    "\n",
    "# Print the full comparison table\n",
    "print('Complete Comparison:')\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "fig = plot_comparison(data, comparison_df)\n",
    "plt.savefig('task5_comparison.png', dpi=150)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd966d70",
   "metadata": {},
   "source": [
    "### Discussion of Task 5 results\n",
    "\n",
    "**1. Can we just use machine learning instead of traditional models?**\n",
    "No, we can't rely only on ML. Machine learning models are like black boxes - we can't really understand why they make certain predictions. They also need lots of data to work well, and they're bad at predicting things outside the range of data they've seen. Traditional disease models like SEIR help us understand *why* an epidemic spreads, which ML can't do.\n",
    "\n",
    "**2. What makes a good prediction?**\n",
    "A good prediction should follow the S-shaped curve that epidemics usually make, correctly guess when the peak happens, and work well for time periods it hasn't seen before. The SEIR model with changing infection rates gives us both good predictions and explanations we can understand.\n",
    "\n",
    "**3. What did we learn?**\n",
    "Using both traditional models and ML together works better than using just one. Which method you pick depends on what you need - use SEIR if you want to understand the disease, use ML for quick short-term guesses, and use traditional models if you're making policy decisions. No single approach can solve everything - we need different tools and expert knowledge working together.\n",
    "\n",
    "### Summary\n",
    "Each method we tested has strengths and weaknesses. The SEIR model is easy to understand and based on real biology, but it needs careful tuning to work well. Linear regression is very simple to use, but it doesn't capture the curved shape of epidemic data. Polynomial fitting is more flexible and can match curved shapes, but it sometimes fits random noise instead of real patterns. Neural networks are good at finding complex patterns in data, but they're hard to interpret - we don't really know why they give certain answers. LSTM networks handle time-based patterns well, but they need a lot of data to train properly, which we often don't have during an outbreak.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254f085f",
   "metadata": {},
   "source": [
    "## **Conclusion and Discussion**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8b057b",
   "metadata": {},
   "source": [
    "## Individual Reflections\n",
    "\n",
    "### Emad Omar Mohamed\n",
    "\n",
    "### Hassan Nehad Adnan\n",
    "\n",
    "### Sture Odin Domingos Troli\n",
    "led Topic 1 and theoretical foundations. Applying K-Means to real images required thinking about practical issues like which features to use and how to encode colors. The hardest part was interpreting what clusters mean astronomically since the computer groups by numbers, not by what stars actually are. This showed why domain knowledge matters even with automated methods. Next time, he would do more systematic experiments instead of trying random things.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95529693",
   "metadata": {},
   "source": [
    "### **References**\n",
    "\n",
    "[1] H. W. Leung and J. Bovy, \"mw_plot: A Python package for plotting Milky Way maps,\" Journal of Open Source Software, vol. 4, no. 38, p. 1338, 2019. Available: https://github.com/henrysky/milkyway_plot \n",
    "\n",
    "[2] A. K. Jain, \"Data clustering: 50 years beyond K-means,\" Pattern Recognition Letters, vol. 31, no. 8, pp. 651-666, 2010. DOI: 10.1016/j.patrec.2009.09.011\n",
    "June 2010 Pattern Recognition Letters 31(8):651-666 DOI:10.1016/j.patrec.2009.09.011 visited Dec 2025\n",
    "\n",
    "[3] J. P. Gardner et al., \"The James Webb Space Telescope,\" Space Science Reviews, vol. 123, no. 4, pp. 485-606, 2006. DOI: 10.1007/s11214-006-8315-7\n",
    "February 2009Space Science Reviews 123(4):485-606 SourceOAI LicenseCC BY-NC 2.0 DOI:10.1007/s11214-006-8315-7 visited Dec 2025\n",
    "\n",
    "[4] M. J. Graham et al., \"Machine Learning for Astronomical Data Analysis,\" Annual Review of Astronomy and Astrophysics, vol. 58, pp. 147-185, 2020. DOI: 10.1146/annurev-astro-091918-104430 April 2019 DOI:10.48550/arXiv.1904.07248 Dec 2025\n",
    "\n",
    "[5] Ž. Ivezić et al., \"Statistics, Data Mining, and Machine Learning in Astronomy: A Practical Python Guide for the Analysis of Survey Data,\" Princeton University Press, 2014. ISBN: 978-0691151687 PDF version of the Book and Article DOI:10.1515/9781400848911 Visited Dec 2025\n",
    "\n",
    "[6] C. J. Lintott et al., \"Galaxy Zoo: morphologies derived from visual inspection of galaxies from the Sloan Digital Sky Survey,\" Monthly Notices of the Royal Astronomical Society, vol. 389, no. 3, pp. 1179-1189, 2008. DOI: 10.1111/j.1365-2966.2008.13689.x\n",
    "\n",
    "[7] D. Baron, \"Machine Learning in Astronomy: A Practical Overview,\" arXiv preprint, arXiv:1904.07248, 2019. Available: https://arxiv.org/abs/1904.07248 \n",
    "DOI:10.48550/arXiv.1904.07248 Visited Dec 2025\n",
    "\n",
    "[8] A. Mellinger, \"A Color All-Sky Panorama Image of the Milky Way,\" Publications of the Astronomical Society of the Pacific, vol. 121, no. 885, pp. 1180-1187, 2009. DOI: 10.1086/648480 Visited Dec 2025\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mod300",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
